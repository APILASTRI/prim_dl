{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from settings import *\n",
    "from scripts import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the image with 320 * 240 size\n",
    "imginfo = []\n",
    "with open(list_file) as f:\n",
    "    for line in f:\n",
    "        temp = line.split()\n",
    "        if temp[1] == '320' and temp[2] == '240':\n",
    "            imginfo.append(temp[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# strat from small part of the data\n",
    "nbsel = 100\n",
    "imginfost = imginfo[0:nbsel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the image and preprocess into 4-dimension matrix (batch, height, width, channel)\n",
    "imgA = np.zeros((nbsel, 240, 320, 3))\n",
    "imgB = np.zeros((nbsel, 120, 160, 3))\n",
    "imgC = np.zeros((nbsel, 60, 80, 3))\n",
    "for i in xrange(len(imginfost)):\n",
    "    img = open_convert(image_dir + imginfost[i][0] + '.jpg', mode='YCbCr')\n",
    "    lplist = laplacian_pyramid(img, 3)\n",
    "    imgA[i] = lplist[0]\n",
    "    imgB[i] = lplist[1]\n",
    "    imgC[i] = lplist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# local contrast normalisation\n",
    "inputA = lecun_lcn_batch(imgA, kernel_shape=15, threshold=1e-4)\n",
    "inputB = lecun_lcn_batch(imgB, kernel_shape=15, threshold=1e-4)\n",
    "inputC = lecun_lcn_batch(imgC, kernel_shape=15, threshold=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the label for every pixel of the image\n",
    "img_label = read_label_batch(label_dir, imginfost, labeltype='regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# translate label into vector\n",
    "label_in = np.zeros([img_label.shape[0], img_label.shape[1], img_label.shape[2], 9])\n",
    "for i in xrange(img_label.shape[0]):\n",
    "    for j in xrange(img_label.shape[1]):\n",
    "        for k in xrange(img_label.shape[2]):\n",
    "            label_in[i, j, k, img_label[i, j, k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.169607\n",
      "step 10, training accuracy 0.21706\n"
     ]
    }
   ],
   "source": [
    "# convolutional neural network\n",
    "trainbatch = 20\n",
    "\n",
    "# conv layer 1\n",
    "# parameter\n",
    "w_conv1_a = weight_variable([7, 7, 1, 10])\n",
    "w_conv1_b = weight_variable([7, 7, 2, 6])\n",
    "b_conv1 = bias_variable([16])\n",
    "# image input\n",
    "x_imageA = tf.placeholder(tf.float32, [trainbatch, 240, 320, 3])\n",
    "x_imageB = tf.placeholder(tf.float32, [trainbatch, 120, 160, 3])\n",
    "x_imageC = tf.placeholder(tf.float32, [trainbatch, 60, 80, 3])\n",
    "# layer node\n",
    "# image class A\n",
    "x_imageA_a = tf.slice(x_imageA, [0, 0, 0, 0], [-1, -1, -1, 1])\n",
    "x_imageA_b = tf.slice(x_imageA, [0, 0, 0, 1], [-1, -1, -1, -1])\n",
    "h_convA1 = tf.concat(3, [conv2d(x_imageA_a, w_conv1_a), conv2d(x_imageA_b, w_conv1_b)]) + b_conv1\n",
    "h_tanhA1 = tf.tanh(h_convA1)\n",
    "h_poolA1 = max_pool_2x2(h_tanhA1)\n",
    "# image class B\n",
    "x_imageB_a = tf.slice(x_imageB, [0, 0, 0, 0], [-1, -1, -1, 1])\n",
    "x_imageB_b = tf.slice(x_imageB, [0, 0, 0, 1], [-1, -1, -1, -1])\n",
    "h_convB1 = tf.concat(3, [conv2d(x_imageB_a, w_conv1_a), conv2d(x_imageB_b, w_conv1_b)]) + b_conv1\n",
    "h_tanhB1 = tf.tanh(h_convB1)\n",
    "h_poolB1 = max_pool_2x2(h_tanhB1)\n",
    "# image class C\n",
    "x_imageC_a = tf.slice(x_imageC, [0, 0, 0, 0], [-1, -1, -1, 1])\n",
    "x_imageC_b = tf.slice(x_imageC, [0, 0, 0, 1], [-1, -1, -1, -1])\n",
    "h_convC1 = tf.concat(3, [conv2d(x_imageC_a, w_conv1_a), conv2d(x_imageC_b, w_conv1_b)]) + b_conv1\n",
    "h_tanhC1 = tf.tanh(h_convC1)\n",
    "h_poolC1 = max_pool_2x2(h_tanhC1)\n",
    "\n",
    "# conv layer 2\n",
    "# parameter\n",
    "w_conv2 = weight_variable([7, 7, 16, 32])\n",
    "b_conv2 = bias_variable([32])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "# layer node\n",
    "# image class A\n",
    "h_poolA1_drop = tf.nn.dropout(h_poolA1, keep_prob)\n",
    "h_convA2 = conv2d(h_poolA1_drop, w_conv2) + b_conv2\n",
    "h_tanhA2 = tf.tanh(h_convA2)\n",
    "h_poolA2 = max_pool_2x2(h_tanhA2)\n",
    "# image class B\n",
    "h_poolB1_drop = tf.nn.dropout(h_poolB1, keep_prob)\n",
    "h_convB2 = conv2d(h_poolB1_drop, w_conv2) + b_conv2\n",
    "h_tanhB2 = tf.tanh(h_convB2)\n",
    "h_poolB2 = max_pool_2x2(h_tanhB2)\n",
    "# image class C\n",
    "h_poolC1_drop = tf.nn.dropout(h_poolC1, keep_prob)\n",
    "h_convC2 = conv2d(h_poolC1_drop, w_conv2) + b_conv2\n",
    "h_tanhC2 = tf.tanh(h_convC2)\n",
    "h_poolC2 = max_pool_2x2(h_tanhC2)\n",
    "\n",
    "# conv layer 3\n",
    "# parameter\n",
    "w_conv3 = weight_variable([7, 7, 32, 64])\n",
    "b_conv3 = bias_variable([64])\n",
    "# layer node\n",
    "# image class A\n",
    "h_poolA2_drop = tf.nn.dropout(h_poolA2, keep_prob)\n",
    "h_convA3 = conv2d(h_poolA2_drop, w_conv3) + b_conv3\n",
    "# image class B\n",
    "h_poolB2_drop = tf.nn.dropout(h_poolB2, keep_prob)\n",
    "h_convB3 = conv2d(h_poolB2_drop, w_conv3) + b_conv3\n",
    "# image class C\n",
    "h_poolC2_drop = tf.nn.dropout(h_poolC2, keep_prob)\n",
    "h_convC3 = conv2d(h_poolC2_drop, w_conv3) + b_conv3\n",
    "\n",
    "# upsampling the image\n",
    "# image class A\n",
    "h_upsampleA = tf.image.resize_images(h_convA3, 240, 320, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# image class B\n",
    "h_upsampleB = tf.image.resize_images(h_convB3, 240, 320, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# image class C\n",
    "h_upsampleC = tf.image.resize_images(h_convC3, 240, 320, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "# concatenate all three class\n",
    "h_upsample = tf.concat(3, [h_upsampleA, h_upsampleB, h_upsampleC])\n",
    "\n",
    "# softmax\n",
    "# parameter\n",
    "w_soft = weight_variable([192, 9])\n",
    "b_soft = bias_variable([9])\n",
    "# layer node\n",
    "h_fc = tf.reshape(h_upsample, [-1, 192])\n",
    "y_out = tf.nn.softmax(tf.matmul(h_fc, w_soft) + b_soft)\n",
    "\n",
    "# train step\n",
    "# label of every pixel\n",
    "y_real = tf.placeholder(tf.float32, [trainbatch, 240, 320, 9])\n",
    "# cost fonction\n",
    "y_in = tf.reshape(y_real, [-1, 9])\n",
    "cross_entropy = -tf.reduce_sum(y_in * tf.log(y_out))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_out,1), tf.argmax(y_in,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in range(301):\n",
    "        sel = np.random.choice(nbsel, trainbatch, replace=False)\n",
    "        if i%10 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_imageA: inputA[sel, :, :, :], \n",
    "                                                      x_imageB: inputB[sel, :, :, :], \n",
    "                                                      x_imageC: inputC[sel, :, :, :], \n",
    "                                                      y_real: label_in[sel, :, :, :], \n",
    "                                                      keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        train_step.run(feed_dict={x_imageA: inputA[sel, :, :, :], \n",
    "                                  x_imageB: inputB[sel, :, :, :], \n",
    "                                  x_imageC: inputC[sel, :, :, :], \n",
    "                                  y_real: label_in[sel, :, :, :], \n",
    "                                  keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
